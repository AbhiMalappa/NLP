{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "1hBMM6Mc_XuMcbK6X4MxZDhpLr8HNEeTc",
      "authorship_tag": "ABX9TyOXNC9zuICIRWS1z4IHkHgi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbhiMalappa/NLP/blob/main/helpdesk_BERT_predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DeaciChZY9tw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e71f0a48-87ed-49bf-de6e-28c5ac93766f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m113.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "from torch import nn\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "! pip install -q streamlit\n",
        "import streamlit as st"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q streamlit\n",
        "import streamlit as st"
      ],
      "metadata": {
        "id": "jbuTt8dS_IDN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# funct to get predictions\n",
        "model_ckpt = \"drive/MyDrive/Colab Notebooks/NLP/trained_model/Finetune_BERT_for_helpdesk_issue_classification\"\n",
        "#model_ckpt = \"drive/MyDrive/Colab Notebooks/NLP/trained_model/V2_Finetune_BERT_for_helpdesk_issue_classification_7_class\"\n",
        "\n",
        "# prediction for all labels\n",
        "def get_pred(text):\n",
        "  device = torch.device(\"cuda\")\n",
        "\n",
        "  #read model\n",
        "  model = AutoModelForSequenceClassification.from_pretrained(model_ckpt).to(device)\n",
        "\n",
        "  # from model config get labels names\n",
        "  labels = model.config.id2label.values()\n",
        "  labels = list(labels)\n",
        "\n",
        "  #tokenize input\n",
        "  tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "  input_encoded = tokenizer(text, return_tensors='pt').to(device)\n",
        "\n",
        "  # get model pred on tokenized input\n",
        "  with torch.no_grad():\n",
        "    outputs = model(**input_encoded) # output is a torch tensor with logit values on gpu\n",
        "\n",
        "  #output logits\n",
        "  logits = outputs.logits[0] # get logit values\n",
        "  #output probs\n",
        "  probabilities = nn.functional.softmax(logits, dim=-1) # convert logit to prob\n",
        "\n",
        "  # return a dic with labels and probs\n",
        "  probabilities = probabilities.cpu().detach().numpy() # convert to numpy on cpu\n",
        "  result = {labels[i]: probabilities[i] for i in range(len(labels))}\n",
        "\n",
        "  return result, #probabilities\n",
        "\n",
        "# prediction return top label\n",
        "def pipeline_clf(text):\n",
        "  device = torch.device(\"cuda\")\n",
        "  clf = pipeline('text-classification',model = model_ckpt)\n",
        "  pipeline_clf_label = clf(text)[0]['label']\n",
        "  pipeline_clf_score = clf(text)[0]['score']\n",
        "  return pipeline_clf_label, pipeline_clf_score\n",
        "\n",
        "# get sentiment\n",
        "def sentiment(text):\n",
        "  sentement_obj = pipeline('text-classification', model = \"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
        "  #sentement_obj = pipeline('sentiment-analysis')\n",
        "  #emotions\n",
        "  #sentement_obj = pipeline(task=\"text-classification\", model=\"SamLowe/roberta-base-go_emotions\", top_k=5)\n",
        "\n",
        "  sentiment = sentement_obj(text)\n",
        "  return sentiment\n",
        "\n",
        "# pass custom input\n",
        "def custom_input(text):\n",
        "  pred_confidence = {}\n",
        "  sentiment_val = sentiment(text)\n",
        "  pred = get_pred(text)[0]\n",
        "  classification_list = ['agent_unprofessional','long_holdtime','multiple_contacts_made','no_resolution','service_portal', 'Others']\n",
        "\n",
        "  for keys in pred:\n",
        "    if keys in classification_list and pred[keys] > 0.2:\n",
        "      pred_confidence[keys] = pred[keys]\n",
        "\n",
        "  if len(pred_confidence) == 0:\n",
        "    pred_confidence['Others'] = 0.3\n",
        "\n",
        "  if sentiment_val[0]['score'] > 0.6:\n",
        "    pred_confidence[sentiment_val[0]['label'] ] = sentiment_val[0]['score']\n",
        "\n",
        "  return pred_confidence, pred\n"
      ],
      "metadata": {
        "id": "od5f84V6oI8c"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predict on new data"
      ],
      "metadata": {
        "id": "SfXHAmJH95fe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add code to split int scentence and then predict"
      ],
      "metadata": {
        "id": "ejEAaE-yoePC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.read_csv('drive/MyDrive/Colab Notebooks/training_text_calssifiaction.csv')\n",
        "df = df.sample(3)\n",
        "\n",
        "# call prediction\n",
        "df['pred_label'] = df['string_value'].apply(lambda x: pipeline_clf(x)[0])\n",
        "df['pred_label_score'] = df['string_value'].apply(lambda x: pipeline_clf(x)[1])\n",
        "df['pred_label'] = np.where(df['pred_label_score'] < 0.6, 'Others', df['pred_label'])\n",
        "\n",
        "df['agent_unprofessional_score'] = df['string_value'].apply(lambda x: get_pred(x)[0]['agent_unprofessional'])\n",
        "df['long_holdtime_score'] = df['string_value'].apply(lambda x: get_pred(x)[0]['long_holdtime'])\n",
        "df['multiple_contacts_made_score'] = df['string_value'].apply(lambda x: get_pred(x)[0]['multiple_contacts_made'])\n",
        "df['no_resolution_score'] = df['string_value'].apply(lambda x: get_pred(x)[0]['no_resolution'])\n",
        "df['service_portal_score'] = df['string_value'].apply(lambda x: get_pred(x)[0]['service_portal'])\n",
        "df['pred_val_all_class'] = df['string_value'].apply(lambda x: get_pred(x))\n",
        "\n",
        "df['sentiment_label'] = df['string_value'].apply(lambda x: sentiment(x)[0]['label'])\n",
        "df['sentiment_score'] = df['string_value'].apply(lambda x: sentiment(x)[0]['score'])\n",
        "\n",
        "df.head(2)"
      ],
      "metadata": {
        "id": "QWD-fRrN9wSK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        },
        "outputId": "e5ed7c39-960c-4acb-b7ca-290291063785"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cuda:0\n",
            "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cuda:0\n",
            "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cuda:0\n",
            "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cuda:0\n",
            "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cuda:0\n",
            "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        string_value       Category  \\\n",
              "240                      He was very patient with me         Others   \n",
              "4768  Issue not resolved, but the ticket was closed.  no_resolution   \n",
              "\n",
              "             pred_label  pred_label_score  agent_unprofessional_score  \\\n",
              "240   positive_feedback          0.691563                    0.119301   \n",
              "4768      no_resolution          0.958546                    0.003521   \n",
              "\n",
              "      long_holdtime_score  multiple_contacts_made_score  no_resolution_score  \\\n",
              "240              0.021455                      0.041322             0.023713   \n",
              "4768             0.003498                      0.008349             0.958546   \n",
              "\n",
              "      service_portal_score                                 pred_val_all_class  \\\n",
              "240               0.014018  ({'agent_unprofessional': 0.11930073, 'long_ho...   \n",
              "4768              0.002351  ({'agent_unprofessional': 0.003520502, 'long_h...   \n",
              "\n",
              "     sentiment_label  sentiment_score  \n",
              "240         positive         0.926954  \n",
              "4768        negative         0.649703  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a3400949-132d-4229-8e09-451fd8713206\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>string_value</th>\n",
              "      <th>Category</th>\n",
              "      <th>pred_label</th>\n",
              "      <th>pred_label_score</th>\n",
              "      <th>agent_unprofessional_score</th>\n",
              "      <th>long_holdtime_score</th>\n",
              "      <th>multiple_contacts_made_score</th>\n",
              "      <th>no_resolution_score</th>\n",
              "      <th>service_portal_score</th>\n",
              "      <th>pred_val_all_class</th>\n",
              "      <th>sentiment_label</th>\n",
              "      <th>sentiment_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>240</th>\n",
              "      <td>He was very patient with me</td>\n",
              "      <td>Others</td>\n",
              "      <td>positive_feedback</td>\n",
              "      <td>0.691563</td>\n",
              "      <td>0.119301</td>\n",
              "      <td>0.021455</td>\n",
              "      <td>0.041322</td>\n",
              "      <td>0.023713</td>\n",
              "      <td>0.014018</td>\n",
              "      <td>({'agent_unprofessional': 0.11930073, 'long_ho...</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.926954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4768</th>\n",
              "      <td>Issue not resolved, but the ticket was closed.</td>\n",
              "      <td>no_resolution</td>\n",
              "      <td>no_resolution</td>\n",
              "      <td>0.958546</td>\n",
              "      <td>0.003521</td>\n",
              "      <td>0.003498</td>\n",
              "      <td>0.008349</td>\n",
              "      <td>0.958546</td>\n",
              "      <td>0.002351</td>\n",
              "      <td>({'agent_unprofessional': 0.003520502, 'long_h...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.649703</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3400949-132d-4229-8e09-451fd8713206')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a3400949-132d-4229-8e09-451fd8713206 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a3400949-132d-4229-8e09-451fd8713206');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-22e3b0c8-3716-4667-a7a3-3eec6f60ecdd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-22e3b0c8-3716-4667-a7a3-3eec6f60ecdd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-22e3b0c8-3716-4667-a7a3-3eec6f60ecdd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"string_value\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"He was very patient with me\",\n          \"Issue not resolved, but the ticket was closed.\",\n          \"on hold for over 35 minutes before i switched to option #1 even though it wasn't a pt-related issue.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Category\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Others\",\n          \"no_resolution\",\n          \"long_holdtime\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_label\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"positive_feedback\",\n          \"no_resolution\",\n          \"long_holdtime\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_label_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16201511623946072,\n        \"min\": 0.6915625929832458,\n        \"max\": 0.9840716123580933,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.6915625929832458,\n          0.9585463404655457,\n          0.9840716123580933\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"agent_unprofessional_score\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.1193007305264473,\n          0.00352050201036036,\n          0.0019069868139922619\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"long_holdtime_score\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.021455444395542145,\n          0.0034975584130734205,\n          0.984071671962738\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"multiple_contacts_made_score\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.041321638971567154,\n          0.008349115960299969,\n          0.004723928868770599\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"no_resolution_score\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.023712681606411934,\n          0.9585463404655457,\n          0.0032727080397307873\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"service_portal_score\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.014018305577337742,\n          0.0023508609738200903,\n          0.0022819365840405226\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_val_all_class\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment_label\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"positive\",\n          \"negative\",\n          \"neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.20817443754778225,\n        \"min\": 0.519332230091095,\n        \"max\": 0.9269535541534424,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9269535541534424,\n          0.6497029066085815,\n          0.519332230091095\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predict on text input"
      ],
      "metadata": {
        "id": "wNz2N0_t-Um0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = [\n",
        "    \" I felt like the service rep was not patient enough to explain what the issue was and how i can prevent it from happening again. Probably having a bad day. I was not satisfied with this service. \"\n",
        "    ]\n",
        "\n",
        "text = [\n",
        "    \"  i want to sleep  \"\n",
        "    ]\n",
        "\n",
        "custom_input(text)[0]\n"
      ],
      "metadata": {
        "id": "XUmNnVXPqOf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c175d13e-4d15-411e-9559-7537795987fe"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'long_holdtime': 0.21355872, 'neutral': 0.7814059257507324}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_pred(text)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ab-4tiVJV0fp",
        "outputId": "85f47238-a4b1-4568-e832-8400017d0347"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Others': 0.026007662,\n",
              " 'agent_unprofessional': 0.040137194,\n",
              " 'long_holdtime': 0.9233131,\n",
              " 'no_resolution': 0.0067846593,\n",
              " 'service_portal': 0.0037572933}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L2ZjSe3TJ-HF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zero-Shot Classification"
      ],
      "metadata": {
        "id": "QzYglg5QpWfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(model=\"facebook/bart-large-mnli\")\n",
        "pipe(\"I had to talk to 3 different IT Support technicians. Got several different view points. The last technician was about to make a few changes that speed up my results. I was happy with that because it took 1 1/2 days to resolve my issue. I was very happy on the last attempt to resolve my problem.\",\n",
        "    candidate_labels=[\"unprofessional\", \"wait\", \"not resolved\", \"positive\", \"negative\", \"multiple contacts\", \"lack knowledge\"],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjS9kzhpnkFO",
        "outputId": "df146980-f76b-4c5c-d2c6-a14bb3d6cdb8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': 'I had to talk to 3 different IT Support technicians. Got several different view points. The last technician was about to make a few changes that speed up my results. I was happy with that because it took 1 1/2 days to resolve my issue. I was very happy on the last attempt to resolve my problem.',\n",
              " 'labels': ['multiple contacts',\n",
              "  'positive',\n",
              "  'wait',\n",
              "  'lack knowledge',\n",
              "  'negative',\n",
              "  'unprofessional',\n",
              "  'not resolved'],\n",
              " 'scores': [0.7935426235198975,\n",
              "  0.15460607409477234,\n",
              "  0.020611831918358803,\n",
              "  0.015902787446975708,\n",
              "  0.007993784733116627,\n",
              "  0.003712371224537492,\n",
              "  0.0036305116955190897]}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZYWoVfMUlP0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1F9xO76TJ-Qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "\n",
        "x = st.slider('Select a value')\n",
        "st.write(x, 'squared is', x * x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYOvyMXE1YMG",
        "outputId": "3ba98e75-c1dd-484b-8a82-139c23d22107"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GLpz0e35NqZ",
        "outputId": "c174701b-a614-4000-9ec9-983c65bc9d4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K\n",
            "added 22 packages in 2s\n",
            "\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com\n",
        "#!curl https://loca.lt/mytunnelpassword\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC9s2NfV7WjN",
        "outputId": "2b8f7254-d8c0-4cb2-a1dc-1f6e60965d77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.48.16.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!streamlit run /content/app.py &>/content/logs.txt &\n",
        "!streamlit run app.py &>/content/logs.txt &\n"
      ],
      "metadata": {
        "id": "N_K4hQE65PiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iK2A0J-65Sk_",
        "outputId": "e2bdc3eb-de43-40c1-ebf4-818b8712a6b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0Kyour url is: https://cute-beers-say.loca.lt\n",
            "y\n",
            "34.48.16.24\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}